{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training doc2vec model\n",
    "\n",
    "Steps:\n",
    "* Tokenize punctuations as if they are their own words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is disabled, cuDNN 5105)\n",
      "/home/anonoz/anaconda2/envs/tensorflow/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import gensim\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Easily changable settings\n",
    "# We will only train from training/unlabeled set\n",
    "text_corpus_files = ['aclImdb/train/pos/*.txt', 'aclImdb/train/neg/*.txt', 'aclImdb/train/unsup/*.txt']\n",
    "word_vector_dims = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #1 Remove HTML (inspired by Kaggle)\n",
    "    text = BeautifulSoup(text, \"html.parser\").getText()\n",
    "\n",
    "    #2 Tokenize (stolen from Yoon Kim's CNN)\n",
    "    text = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", text)     \n",
    "    text = re.sub(r\"\\'s\", \" \\'s\", text) \n",
    "    text = re.sub(r\"\\'ve\", \" \\'ve\", text) \n",
    "    text = re.sub(r\"n\\'t\", \" n\\'t\", text) \n",
    "    text = re.sub(r\"\\'re\", \" \\'re\", text) \n",
    "    text = re.sub(r\"\\'d\", \" \\'d\", text) \n",
    "    text = re.sub(r\"\\'ll\", \" \\'ll\", text) \n",
    "    text = re.sub(r\",\", \" , \", text) \n",
    "    text = re.sub(r\"!\", \" ! \", text) \n",
    "    text = re.sub(r\"\\(\", \" \\( \", text) \n",
    "    text = re.sub(r\"\\)\", \" \\) \", text) \n",
    "    text = re.sub(r\"\\?\", \" \\? \", text) \n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    #3 Lower cap\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_text_list(text_list, pad_token=\"<PAD/>\", pad_width=0):\n",
    "    return text_list + ([pad_token] * (pad_width - len(text_list)))\n",
    "\n",
    "def text_to_padded_list(text, pad_token=\"<PAD/>\", pad_width=0):\n",
    "    text_list = preprocess_text(text).split()\n",
    "    return pad_text_list(text_list, pad_token, pad_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file 75000\n",
      "Longest text list: 2773\n"
     ]
    }
   ],
   "source": [
    "processed_texts = []\n",
    "file_names = []\n",
    "file_count = 0\n",
    "for folder_files in text_corpus_files:\n",
    "    for text_file in glob.glob(folder_files):\n",
    "        with(open(text_file, 'r')) as f:\n",
    "            processed_texts.append(text_to_padded_list(f.read()))\n",
    "            file_names.append(text_file)\n",
    "            file_count += 1\n",
    "            if file_count % 100 == 0:\n",
    "                sys.stdout.write('\\rLoading text file {0:d}'.format(file_count))\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "max_processed_text_len = len(max(processed_texts, key=len))\n",
    "print('\\nLongest text list: {0:d}'.format(max_processed_text_len))\n",
    "# for i, text_list in enumerate(processed_texts):\n",
    "#     processed_texts[i] = pad_text_list(text_list, pad_width=max_processed_text_len)\n",
    "#     if (i + 1) % 1000 == 0:\n",
    "#         sys.stdout.write('\\rPadding text list {0:d}'.format(i+1))\n",
    "#         sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LabeledReview(object):\n",
    "    def __init__(self, docs_list, labels_list):\n",
    "        self.docs_list = docs_list\n",
    "        self.labels_list = labels_list\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.docs_list):\n",
    "            yield TaggedDocument(words=doc, tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning epoch 1\n",
      "Beginning epoch 2\n",
      "Beginning epoch 3\n",
      "Beginning epoch 4\n",
      "Beginning epoch 5\n",
      "Beginning epoch 6\n",
      "Beginning epoch 7\n",
      "Beginning epoch 8\n",
      "Beginning epoch 9\n",
      "Beginning epoch 10\n",
      "--- 1517.59330988 seconds ---\n"
     ]
    }
   ],
   "source": [
    "it = LabeledReview(processed_texts, file_names)\n",
    "\n",
    "model = Doc2Vec(size=100, window=8, min_count=1, workers=4, alpha=0.025, min_alpha=0.025, dm=1)\n",
    "model.build_vocab(it)\n",
    "\n",
    "# TIMER\n",
    "import time\n",
    "start_time = time.time()\n",
    "# END TIMER\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"Beginning epoch {0:d}\".format(epoch+1))\n",
    "    model.train(it)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha\n",
    "    model.train(it)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.save_word2vec_format('word2vec/d2v-dm-100d.bin', binary=True)\n",
    "model.save('word2vec/d2v-dm-100d.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
