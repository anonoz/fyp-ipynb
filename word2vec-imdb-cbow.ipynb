{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec with how Yoon Kim did it\n",
    "\n",
    "Steps:\n",
    "* Tokenize punctuations as if they are their own words\n",
    "* Determine the longest review's word count, then pad other reviews so that they are all as long as the longest review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is disabled, cuDNN 5105)\n",
      "/home/anonoz/anaconda2/envs/tensorflow/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import gensim\n",
    "import logging\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Easily changable settings\n",
    "text_corpus_files = ['aclImdb/train/pos/*.txt', 'aclImdb/train/neg/*.txt', 'aclImdb/train/unsup/*.txt']\n",
    "word_vector_dims = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #1 Remove HTML (inspired by Kaggle)\n",
    "    text = BeautifulSoup(text, \"html.parser\").getText()\n",
    "\n",
    "    #2 Tokenize (stolen from Yoon Kim's CNN)\n",
    "    text = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", text)     \n",
    "    text = re.sub(r\"\\'s\", \" \\'s\", text) \n",
    "    text = re.sub(r\"\\'ve\", \" \\'ve\", text) \n",
    "    text = re.sub(r\"n\\'t\", \" n\\'t\", text) \n",
    "    text = re.sub(r\"\\'re\", \" \\'re\", text) \n",
    "    text = re.sub(r\"\\'d\", \" \\'d\", text) \n",
    "    text = re.sub(r\"\\'ll\", \" \\'ll\", text) \n",
    "    text = re.sub(r\",\", \" , \", text) \n",
    "    text = re.sub(r\"!\", \" ! \", text) \n",
    "    text = re.sub(r\"\\(\", \" \\( \", text) \n",
    "    text = re.sub(r\"\\)\", \" \\) \", text) \n",
    "    text = re.sub(r\"\\?\", \" \\? \", text) \n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    #3 Lower cap\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_text_list(text_list, pad_token=\"<PAD/>\", pad_width=0):\n",
    "    return text_list + ([pad_token] * (pad_width - len(text_list)))\n",
    "\n",
    "def text_to_padded_list(text, pad_token=\"<PAD/>\", pad_width=0):\n",
    "    text_list = preprocess_text(text).split()\n",
    "    return pad_text_list(text_list, pad_token, pad_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file 75000\n",
      "Longest text list: 2773\n",
      "Padding text list 75000"
     ]
    }
   ],
   "source": [
    "processed_texts = []\n",
    "file_count = 0\n",
    "for folder_files in text_corpus_files:\n",
    "    for text_file in glob.glob(folder_files):\n",
    "        with(open(text_file, 'r')) as f:\n",
    "            processed_texts.append(text_to_padded_list(f.read()))\n",
    "            file_count += 1\n",
    "            if file_count % 100 == 0:\n",
    "                sys.stdout.write('\\rLoading text file {0:d}'.format(file_count))\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "max_processed_text_len = len(max(processed_texts, key=len))\n",
    "print('\\nLongest text list: {0:d}'.format(max_processed_text_len))\n",
    "for i, text_list in enumerate(processed_texts):\n",
    "    processed_texts[i] = pad_text_list(text_list, pad_width=max_processed_text_len)\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        sys.stdout.write('\\rPadding text list {0:d}'.format(i+1))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-01 18:27:51,080 : INFO : collecting all words and their counts\n",
      "2016-10-01 18:27:51,081 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2016-10-01 18:27:52,742 : INFO : PROGRESS: at sentence #10000, processed 27730000 words, keeping 54831 word types\n",
      "2016-10-01 18:27:54,398 : INFO : PROGRESS: at sentence #20000, processed 55460000 words, keeping 74809 word types\n",
      "2016-10-01 18:27:56,064 : INFO : PROGRESS: at sentence #30000, processed 83190000 words, keeping 90742 word types\n",
      "2016-10-01 18:27:57,745 : INFO : PROGRESS: at sentence #40000, processed 110920000 words, keeping 105208 word types\n",
      "2016-10-01 18:27:59,426 : INFO : PROGRESS: at sentence #50000, processed 138650000 words, keeping 116872 word types\n",
      "2016-10-01 18:28:01,115 : INFO : PROGRESS: at sentence #60000, processed 166380000 words, keeping 127656 word types\n",
      "2016-10-01 18:28:02,794 : INFO : PROGRESS: at sentence #70000, processed 194110000 words, keeping 136901 word types\n",
      "2016-10-01 18:28:03,639 : INFO : collected 141295 word types from a corpus of 207975000 raw words and 75000 sentences\n",
      "2016-10-01 18:28:05,083 : INFO : min_count=1 retains 141295 unique words (drops 0)\n",
      "2016-10-01 18:28:05,084 : INFO : min_count leaves 207975000 word corpus (100% of original 207975000)\n",
      "2016-10-01 18:28:05,335 : INFO : deleting the raw counts dictionary of 141295 items\n",
      "2016-10-01 18:28:05,339 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2016-10-01 18:28:05,339 : INFO : downsampling leaves estimated 24972290 word corpus (12.0% of prior 207975000)\n",
      "2016-10-01 18:28:05,340 : INFO : estimated required memory for 141295 words and 100 dimensions: 183683500 bytes\n",
      "2016-10-01 18:28:05,679 : INFO : resetting layer weights\n",
      "2016-10-01 18:28:06,887 : INFO : training model with 4 workers on 141295 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2016-10-01 18:28:06,887 : INFO : expecting 75000 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-10-01 18:28:07,892 : INFO : PROGRESS: at 0.61% examples, 781964 words/s, in_qsize 8, out_qsize 3\n",
      "2016-10-01 18:28:08,892 : INFO : PROGRESS: at 1.24% examples, 780239 words/s, in_qsize 7, out_qsize 3\n",
      "2016-10-01 18:28:09,893 : INFO : PROGRESS: at 1.86% examples, 785310 words/s, in_qsize 5, out_qsize 2\n",
      "2016-10-01 18:28:10,894 : INFO : PROGRESS: at 2.49% examples, 784560 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:28:11,895 : INFO : PROGRESS: at 3.12% examples, 782209 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:28:12,897 : INFO : PROGRESS: at 3.74% examples, 781314 words/s, in_qsize 8, out_qsize 3\n",
      "2016-10-01 18:28:13,898 : INFO : PROGRESS: at 4.37% examples, 781250 words/s, in_qsize 5, out_qsize 1\n",
      "2016-10-01 18:28:14,899 : INFO : PROGRESS: at 5.00% examples, 780857 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:28:15,900 : INFO : PROGRESS: at 5.63% examples, 781223 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:28:16,902 : INFO : PROGRESS: at 6.26% examples, 780091 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:28:17,906 : INFO : PROGRESS: at 6.89% examples, 779013 words/s, in_qsize 7, out_qsize 4\n",
      "2016-10-01 18:28:18,907 : INFO : PROGRESS: at 7.52% examples, 778867 words/s, in_qsize 4, out_qsize 4\n",
      "2016-10-01 18:28:19,915 : INFO : PROGRESS: at 8.15% examples, 779334 words/s, in_qsize 3, out_qsize 8\n",
      "2016-10-01 18:28:20,916 : INFO : PROGRESS: at 8.79% examples, 780377 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:28:21,919 : INFO : PROGRESS: at 9.42% examples, 780527 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:28:22,919 : INFO : PROGRESS: at 10.03% examples, 780044 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:28:23,921 : INFO : PROGRESS: at 10.66% examples, 780553 words/s, in_qsize 6, out_qsize 1\n",
      "2016-10-01 18:28:24,922 : INFO : PROGRESS: at 11.28% examples, 780565 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:28:25,923 : INFO : PROGRESS: at 11.91% examples, 780963 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:28:26,923 : INFO : PROGRESS: at 12.54% examples, 781159 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:28:27,927 : INFO : PROGRESS: at 13.17% examples, 781514 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:28:28,928 : INFO : PROGRESS: at 13.79% examples, 782023 words/s, in_qsize 5, out_qsize 2\n",
      "2016-10-01 18:28:29,929 : INFO : PROGRESS: at 14.42% examples, 781821 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:28:30,936 : INFO : PROGRESS: at 15.04% examples, 781690 words/s, in_qsize 0, out_qsize 7\n",
      "2016-10-01 18:28:31,934 : INFO : PROGRESS: at 15.66% examples, 781591 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:28:32,936 : INFO : PROGRESS: at 16.29% examples, 781104 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:28:33,936 : INFO : PROGRESS: at 16.92% examples, 780575 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:28:34,939 : INFO : PROGRESS: at 17.54% examples, 780459 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:28:35,938 : INFO : PROGRESS: at 18.16% examples, 780528 words/s, in_qsize 5, out_qsize 3\n",
      "2016-10-01 18:28:36,941 : INFO : PROGRESS: at 18.78% examples, 780370 words/s, in_qsize 8, out_qsize 5\n",
      "2016-10-01 18:28:37,941 : INFO : PROGRESS: at 19.41% examples, 780790 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:28:38,941 : INFO : PROGRESS: at 20.04% examples, 780777 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:28:39,942 : INFO : PROGRESS: at 20.67% examples, 781221 words/s, in_qsize 6, out_qsize 0\n",
      "2016-10-01 18:28:40,944 : INFO : PROGRESS: at 21.30% examples, 781217 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:28:41,947 : INFO : PROGRESS: at 21.92% examples, 781760 words/s, in_qsize 6, out_qsize 1\n",
      "2016-10-01 18:28:42,950 : INFO : PROGRESS: at 22.55% examples, 781782 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:28:43,950 : INFO : PROGRESS: at 23.17% examples, 781365 words/s, in_qsize 8, out_qsize 7\n",
      "2016-10-01 18:28:44,951 : INFO : PROGRESS: at 23.80% examples, 781497 words/s, in_qsize 3, out_qsize 1\n",
      "2016-10-01 18:28:45,951 : INFO : PROGRESS: at 24.43% examples, 781232 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:28:46,952 : INFO : PROGRESS: at 25.05% examples, 781107 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:28:47,954 : INFO : PROGRESS: at 25.68% examples, 781062 words/s, in_qsize 5, out_qsize 5\n",
      "2016-10-01 18:28:48,953 : INFO : PROGRESS: at 26.31% examples, 780955 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:28:49,956 : INFO : PROGRESS: at 26.94% examples, 780767 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:28:50,954 : INFO : PROGRESS: at 27.57% examples, 780563 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:28:51,957 : INFO : PROGRESS: at 28.19% examples, 780554 words/s, in_qsize 6, out_qsize 5\n",
      "2016-10-01 18:28:52,955 : INFO : PROGRESS: at 28.82% examples, 780441 words/s, in_qsize 7, out_qsize 3\n",
      "2016-10-01 18:28:53,959 : INFO : PROGRESS: at 29.45% examples, 780596 words/s, in_qsize 6, out_qsize 2\n",
      "2016-10-01 18:28:54,959 : INFO : PROGRESS: at 30.07% examples, 780617 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:28:55,960 : INFO : PROGRESS: at 30.70% examples, 780796 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:28:56,961 : INFO : PROGRESS: at 31.32% examples, 780683 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:28:57,970 : INFO : PROGRESS: at 31.94% examples, 780657 words/s, in_qsize 6, out_qsize 7\n",
      "2016-10-01 18:28:58,963 : INFO : PROGRESS: at 32.56% examples, 780704 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:28:59,964 : INFO : PROGRESS: at 33.19% examples, 780613 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:00,966 : INFO : PROGRESS: at 33.81% examples, 780821 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:01,965 : INFO : PROGRESS: at 34.43% examples, 780646 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:29:02,974 : INFO : PROGRESS: at 35.05% examples, 780567 words/s, in_qsize 6, out_qsize 5\n",
      "2016-10-01 18:29:03,971 : INFO : PROGRESS: at 35.67% examples, 780516 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:29:04,975 : INFO : PROGRESS: at 36.30% examples, 780479 words/s, in_qsize 3, out_qsize 2\n",
      "2016-10-01 18:29:05,972 : INFO : PROGRESS: at 36.93% examples, 780263 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:06,974 : INFO : PROGRESS: at 37.55% examples, 780284 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:29:07,974 : INFO : PROGRESS: at 38.17% examples, 780166 words/s, in_qsize 6, out_qsize 1\n",
      "2016-10-01 18:29:08,976 : INFO : PROGRESS: at 38.79% examples, 780078 words/s, in_qsize 6, out_qsize 1\n",
      "2016-10-01 18:29:09,978 : INFO : PROGRESS: at 39.41% examples, 780138 words/s, in_qsize 5, out_qsize 1\n",
      "2016-10-01 18:29:10,977 : INFO : PROGRESS: at 40.04% examples, 780065 words/s, in_qsize 8, out_qsize 3\n",
      "2016-10-01 18:29:11,978 : INFO : PROGRESS: at 40.67% examples, 780334 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:12,980 : INFO : PROGRESS: at 41.29% examples, 780325 words/s, in_qsize 6, out_qsize 1\n",
      "2016-10-01 18:29:13,980 : INFO : PROGRESS: at 41.91% examples, 780415 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:14,984 : INFO : PROGRESS: at 42.53% examples, 780393 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:29:15,986 : INFO : PROGRESS: at 43.16% examples, 780256 words/s, in_qsize 6, out_qsize 2\n",
      "2016-10-01 18:29:16,986 : INFO : PROGRESS: at 43.78% examples, 780262 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:29:17,988 : INFO : PROGRESS: at 44.42% examples, 780261 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:18,988 : INFO : PROGRESS: at 45.04% examples, 780217 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:19,991 : INFO : PROGRESS: at 45.67% examples, 780207 words/s, in_qsize 7, out_qsize 4\n",
      "2016-10-01 18:29:20,995 : INFO : PROGRESS: at 46.29% examples, 780042 words/s, in_qsize 7, out_qsize 4\n",
      "2016-10-01 18:29:21,995 : INFO : PROGRESS: at 46.92% examples, 779904 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:29:22,997 : INFO : PROGRESS: at 47.54% examples, 779755 words/s, in_qsize 6, out_qsize 4\n",
      "2016-10-01 18:29:23,996 : INFO : PROGRESS: at 48.18% examples, 779836 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:24,995 : INFO : PROGRESS: at 48.80% examples, 779845 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:25,997 : INFO : PROGRESS: at 49.42% examples, 779740 words/s, in_qsize 8, out_qsize 3\n",
      "2016-10-01 18:29:27,000 : INFO : PROGRESS: at 50.04% examples, 779743 words/s, in_qsize 7, out_qsize 3\n",
      "2016-10-01 18:29:28,001 : INFO : PROGRESS: at 50.66% examples, 779689 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:29,005 : INFO : PROGRESS: at 51.29% examples, 779716 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:29:30,003 : INFO : PROGRESS: at 51.90% examples, 779697 words/s, in_qsize 8, out_qsize 4\n",
      "2016-10-01 18:29:31,007 : INFO : PROGRESS: at 52.53% examples, 779707 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:29:32,009 : INFO : PROGRESS: at 53.15% examples, 779679 words/s, in_qsize 6, out_qsize 2\n",
      "2016-10-01 18:29:33,006 : INFO : PROGRESS: at 53.77% examples, 779792 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:34,011 : INFO : PROGRESS: at 54.40% examples, 779706 words/s, in_qsize 3, out_qsize 6\n",
      "2016-10-01 18:29:35,009 : INFO : PROGRESS: at 55.02% examples, 779822 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:36,012 : INFO : PROGRESS: at 55.65% examples, 779851 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:29:37,010 : INFO : PROGRESS: at 56.28% examples, 779742 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:38,010 : INFO : PROGRESS: at 56.90% examples, 779561 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:29:39,012 : INFO : PROGRESS: at 57.52% examples, 779581 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:40,014 : INFO : PROGRESS: at 58.14% examples, 779597 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:41,016 : INFO : PROGRESS: at 58.77% examples, 779529 words/s, in_qsize 6, out_qsize 2\n",
      "2016-10-01 18:29:42,018 : INFO : PROGRESS: at 59.39% examples, 779602 words/s, in_qsize 7, out_qsize 4\n",
      "2016-10-01 18:29:43,017 : INFO : PROGRESS: at 60.02% examples, 779595 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:29:44,019 : INFO : PROGRESS: at 60.64% examples, 779701 words/s, in_qsize 5, out_qsize 2\n",
      "2016-10-01 18:29:45,018 : INFO : PROGRESS: at 61.26% examples, 779626 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:46,018 : INFO : PROGRESS: at 61.88% examples, 779784 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:47,020 : INFO : PROGRESS: at 62.51% examples, 779817 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:48,020 : INFO : PROGRESS: at 63.13% examples, 779716 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:49,022 : INFO : PROGRESS: at 63.76% examples, 779712 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:29:50,024 : INFO : PROGRESS: at 64.39% examples, 779638 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:51,024 : INFO : PROGRESS: at 65.01% examples, 779595 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:52,026 : INFO : PROGRESS: at 65.64% examples, 779631 words/s, in_qsize 5, out_qsize 2\n",
      "2016-10-01 18:29:53,025 : INFO : PROGRESS: at 66.27% examples, 779588 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:29:54,026 : INFO : PROGRESS: at 66.89% examples, 779376 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:29:55,027 : INFO : PROGRESS: at 67.52% examples, 779354 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:29:56,028 : INFO : PROGRESS: at 68.13% examples, 779311 words/s, in_qsize 5, out_qsize 3\n",
      "2016-10-01 18:29:57,029 : INFO : PROGRESS: at 68.76% examples, 779312 words/s, in_qsize 5, out_qsize 3\n",
      "2016-10-01 18:29:58,031 : INFO : PROGRESS: at 69.38% examples, 779246 words/s, in_qsize 7, out_qsize 6\n",
      "2016-10-01 18:29:59,032 : INFO : PROGRESS: at 70.01% examples, 779322 words/s, in_qsize 8, out_qsize 3\n",
      "2016-10-01 18:30:00,035 : INFO : PROGRESS: at 70.64% examples, 779381 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:30:01,037 : INFO : PROGRESS: at 71.26% examples, 779347 words/s, in_qsize 3, out_qsize 0\n",
      "2016-10-01 18:30:02,039 : INFO : PROGRESS: at 71.88% examples, 779365 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:30:03,041 : INFO : PROGRESS: at 72.51% examples, 779438 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:30:04,041 : INFO : PROGRESS: at 73.13% examples, 779409 words/s, in_qsize 5, out_qsize 1\n",
      "2016-10-01 18:30:05,045 : INFO : PROGRESS: at 73.75% examples, 779455 words/s, in_qsize 6, out_qsize 2\n",
      "2016-10-01 18:30:06,043 : INFO : PROGRESS: at 74.38% examples, 779425 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:30:07,048 : INFO : PROGRESS: at 75.00% examples, 779466 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:30:08,049 : INFO : PROGRESS: at 75.62% examples, 779425 words/s, in_qsize 5, out_qsize 3\n",
      "2016-10-01 18:30:09,049 : INFO : PROGRESS: at 76.25% examples, 779372 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:30:10,051 : INFO : PROGRESS: at 76.87% examples, 779275 words/s, in_qsize 6, out_qsize 2\n",
      "2016-10-01 18:30:11,050 : INFO : PROGRESS: at 77.50% examples, 779312 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:30:12,050 : INFO : PROGRESS: at 78.12% examples, 779300 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:30:13,054 : INFO : PROGRESS: at 78.74% examples, 779252 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-01 18:30:14,056 : INFO : PROGRESS: at 79.36% examples, 779310 words/s, in_qsize 8, out_qsize 3\n",
      "2016-10-01 18:30:15,058 : INFO : PROGRESS: at 79.99% examples, 779285 words/s, in_qsize 6, out_qsize 2\n",
      "2016-10-01 18:30:16,059 : INFO : PROGRESS: at 80.62% examples, 779428 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:30:17,060 : INFO : PROGRESS: at 81.24% examples, 779375 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:30:18,062 : INFO : PROGRESS: at 81.87% examples, 779554 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:30:19,064 : INFO : PROGRESS: at 82.50% examples, 779590 words/s, in_qsize 4, out_qsize 1\n",
      "2016-10-01 18:30:20,066 : INFO : PROGRESS: at 83.12% examples, 779555 words/s, in_qsize 7, out_qsize 3\n",
      "2016-10-01 18:30:21,065 : INFO : PROGRESS: at 83.75% examples, 779579 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:30:22,066 : INFO : PROGRESS: at 84.38% examples, 779532 words/s, in_qsize 6, out_qsize 1\n",
      "2016-10-01 18:30:23,071 : INFO : PROGRESS: at 85.01% examples, 779542 words/s, in_qsize 1, out_qsize 1\n",
      "2016-10-01 18:30:24,069 : INFO : PROGRESS: at 85.63% examples, 779555 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:30:25,073 : INFO : PROGRESS: at 86.26% examples, 779481 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:30:26,072 : INFO : PROGRESS: at 86.90% examples, 779444 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:30:27,077 : INFO : PROGRESS: at 87.52% examples, 779356 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:30:28,082 : INFO : PROGRESS: at 88.15% examples, 779369 words/s, in_qsize 2, out_qsize 3\n",
      "2016-10-01 18:30:29,082 : INFO : PROGRESS: at 88.77% examples, 779369 words/s, in_qsize 3, out_qsize 0\n",
      "2016-10-01 18:30:30,083 : INFO : PROGRESS: at 89.39% examples, 779286 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-01 18:30:31,085 : INFO : PROGRESS: at 90.01% examples, 779281 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:30:32,085 : INFO : PROGRESS: at 90.63% examples, 779284 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:30:33,085 : INFO : PROGRESS: at 91.25% examples, 779244 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:30:34,087 : INFO : PROGRESS: at 91.87% examples, 779259 words/s, in_qsize 5, out_qsize 0\n",
      "2016-10-01 18:30:35,089 : INFO : PROGRESS: at 92.49% examples, 779277 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:30:36,088 : INFO : PROGRESS: at 93.11% examples, 779220 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-01 18:30:37,093 : INFO : PROGRESS: at 93.73% examples, 779251 words/s, in_qsize 7, out_qsize 5\n",
      "2016-10-01 18:30:38,094 : INFO : PROGRESS: at 94.35% examples, 779227 words/s, in_qsize 5, out_qsize 8\n",
      "2016-10-01 18:30:39,096 : INFO : PROGRESS: at 94.98% examples, 779243 words/s, in_qsize 8, out_qsize 4\n",
      "2016-10-01 18:30:40,096 : INFO : PROGRESS: at 95.60% examples, 779242 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:30:41,098 : INFO : PROGRESS: at 96.23% examples, 779201 words/s, in_qsize 5, out_qsize 2\n",
      "2016-10-01 18:30:42,096 : INFO : PROGRESS: at 96.85% examples, 779118 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-01 18:30:43,098 : INFO : PROGRESS: at 97.47% examples, 779103 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-01 18:30:44,099 : INFO : PROGRESS: at 98.09% examples, 779115 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:30:45,101 : INFO : PROGRESS: at 98.72% examples, 779123 words/s, in_qsize 6, out_qsize 3\n",
      "2016-10-01 18:30:46,103 : INFO : PROGRESS: at 99.35% examples, 779170 words/s, in_qsize 8, out_qsize 3\n",
      "2016-10-01 18:30:47,104 : INFO : PROGRESS: at 99.97% examples, 779139 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-01 18:30:47,142 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-10-01 18:30:47,144 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-10-01 18:30:47,144 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-10-01 18:30:47,145 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-10-01 18:30:47,145 : INFO : training on 1039875000 raw words (124864635 effective words) took 160.3s, 779154 effective words/s\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = gensim.models.Word2Vec(processed_texts, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-01 18:32:05,026 : INFO : storing 141295x100 projection weights into word2vec/w2v-padded.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_word2vec_format('word2vec/w2v-padded.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model = gensim.models.Word2Vec.load_word2vec_format('word2vec/w2v-padded.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
