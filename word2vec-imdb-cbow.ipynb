{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train word2vec\n",
    "\n",
    "Steps:\n",
    "* Tokenize punctuations as if they are their own words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is disabled, cuDNN 5105)\n",
      "/home/anonoz/anaconda2/envs/tensorflow/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import gensim\n",
    "import logging\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Easily changable settings\n",
    "text_corpus_files = ['aclImdb/train/pos/*.txt', 'aclImdb/train/neg/*.txt', 'aclImdb/train/unsup/*.txt']\n",
    "word_vector_dims = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #1 Remove HTML (inspired by Kaggle)\n",
    "    text = BeautifulSoup(text, \"html.parser\").getText()\n",
    "\n",
    "    #2 Tokenize (stolen from Yoon Kim's CNN)\n",
    "    text = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", text)     \n",
    "    text = re.sub(r\"\\'s\", \" \\'s\", text) \n",
    "    text = re.sub(r\"\\'ve\", \" \\'ve\", text) \n",
    "    text = re.sub(r\"n\\'t\", \" n\\'t\", text) \n",
    "    text = re.sub(r\"\\'re\", \" \\'re\", text) \n",
    "    text = re.sub(r\"\\'d\", \" \\'d\", text) \n",
    "    text = re.sub(r\"\\'ll\", \" \\'ll\", text) \n",
    "    text = re.sub(r\",\", \" , \", text) \n",
    "    text = re.sub(r\"!\", \" ! \", text) \n",
    "    text = re.sub(r\"\\(\", \" \\( \", text) \n",
    "    text = re.sub(r\"\\)\", \" \\) \", text) \n",
    "    text = re.sub(r\"\\?\", \" \\? \", text) \n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    #3 Lower cap\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_text_list(text_list, pad_token=\"<PAD/>\", pad_width=0):\n",
    "    return text_list + ([pad_token] * (pad_width - len(text_list)))\n",
    "\n",
    "def text_to_padded_list(text, pad_token=\"<PAD/>\", pad_width=0):\n",
    "    text_list = preprocess_text(text).split()\n",
    "    return pad_text_list(text_list, pad_token, pad_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file 75000\n",
      "Longest text list: 2773\n",
      "Padding text list 75000"
     ]
    }
   ],
   "source": [
    "processed_texts = []\n",
    "file_count = 0\n",
    "for folder_files in text_corpus_files:\n",
    "    for text_file in glob.glob(folder_files):\n",
    "        with(open(text_file, 'r')) as f:\n",
    "            processed_texts.append(text_to_padded_list(f.read()))\n",
    "            file_count += 1\n",
    "            if file_count % 100 == 0:\n",
    "                sys.stdout.write('\\rLoading text file {0:d}'.format(file_count))\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "max_processed_text_len = len(max(processed_texts, key=len))\n",
    "print('\\nLongest text list: {0:d}'.format(max_processed_text_len))\n",
    "for i, text_list in enumerate(processed_texts):\n",
    "    processed_texts[i] = pad_text_list(text_list, pad_width=max_processed_text_len)\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        sys.stdout.write('\\rPadding text list {0:d}'.format(i+1))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-01 19:33:42,311 : INFO : collecting all words and their counts\n",
      "2017-02-01 19:33:42,312 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-01 19:33:44,110 : INFO : PROGRESS: at sentence #10000, processed 27730000 words, keeping 54663 word types\n",
      "2017-02-01 19:33:45,908 : INFO : PROGRESS: at sentence #20000, processed 55460000 words, keeping 74760 word types\n",
      "2017-02-01 19:33:47,734 : INFO : PROGRESS: at sentence #30000, processed 83190000 words, keeping 90929 word types\n",
      "2017-02-01 19:33:49,603 : INFO : PROGRESS: at sentence #40000, processed 110920000 words, keeping 105430 word types\n",
      "2017-02-01 19:33:51,438 : INFO : PROGRESS: at sentence #50000, processed 138650000 words, keeping 117189 word types\n",
      "2017-02-01 19:33:53,309 : INFO : PROGRESS: at sentence #60000, processed 166380000 words, keeping 127458 word types\n",
      "2017-02-01 19:33:55,245 : INFO : PROGRESS: at sentence #70000, processed 194110000 words, keeping 137015 word types\n",
      "2017-02-01 19:33:56,221 : INFO : collected 141295 word types from a corpus of 207975000 raw words and 75000 sentences\n",
      "2017-02-01 19:33:57,805 : INFO : min_count=1 retains 141295 unique words (drops 0)\n",
      "2017-02-01 19:33:57,805 : INFO : min_count leaves 207975000 word corpus (100% of original 207975000)\n",
      "2017-02-01 19:33:58,069 : INFO : deleting the raw counts dictionary of 141295 items\n",
      "2017-02-01 19:33:58,073 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2017-02-01 19:33:58,074 : INFO : downsampling leaves estimated 24972290 word corpus (12.0% of prior 207975000)\n",
      "2017-02-01 19:33:58,074 : INFO : estimated required memory for 141295 words and 100 dimensions: 183683500 bytes\n",
      "2017-02-01 19:33:58,417 : INFO : resetting layer weights\n",
      "2017-02-01 19:33:59,691 : INFO : training model with 4 workers on 141295 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-02-01 19:33:59,692 : INFO : expecting 75000 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-01 19:34:00,695 : INFO : PROGRESS: at 0.59% examples, 750607 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:01,704 : INFO : PROGRESS: at 1.20% examples, 759739 words/s, in_qsize 8, out_qsize 4\n",
      "2017-02-01 19:34:02,703 : INFO : PROGRESS: at 1.68% examples, 707596 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:03,706 : INFO : PROGRESS: at 2.24% examples, 702302 words/s, in_qsize 4, out_qsize 3\n",
      "2017-02-01 19:34:04,706 : INFO : PROGRESS: at 2.85% examples, 716384 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:05,712 : INFO : PROGRESS: at 3.45% examples, 720029 words/s, in_qsize 6, out_qsize 7\n",
      "2017-02-01 19:34:06,713 : INFO : PROGRESS: at 4.04% examples, 723740 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:07,716 : INFO : PROGRESS: at 4.61% examples, 719259 words/s, in_qsize 5, out_qsize 3\n",
      "2017-02-01 19:34:08,717 : INFO : PROGRESS: at 5.23% examples, 722812 words/s, in_qsize 6, out_qsize 5\n",
      "2017-02-01 19:34:09,715 : INFO : PROGRESS: at 5.76% examples, 716911 words/s, in_qsize 8, out_qsize 2\n",
      "2017-02-01 19:34:10,717 : INFO : PROGRESS: at 6.24% examples, 705327 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:34:11,721 : INFO : PROGRESS: at 6.83% examples, 708433 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:34:12,720 : INFO : PROGRESS: at 7.40% examples, 708993 words/s, in_qsize 7, out_qsize 2\n",
      "2017-02-01 19:34:13,721 : INFO : PROGRESS: at 7.97% examples, 709784 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:14,722 : INFO : PROGRESS: at 8.50% examples, 706199 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:15,722 : INFO : PROGRESS: at 9.03% examples, 703627 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:16,726 : INFO : PROGRESS: at 9.64% examples, 707049 words/s, in_qsize 5, out_qsize 3\n",
      "2017-02-01 19:34:17,729 : INFO : PROGRESS: at 10.25% examples, 710485 words/s, in_qsize 7, out_qsize 3\n",
      "2017-02-01 19:34:18,728 : INFO : PROGRESS: at 10.86% examples, 713800 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:19,730 : INFO : PROGRESS: at 11.48% examples, 716337 words/s, in_qsize 6, out_qsize 4\n",
      "2017-02-01 19:34:20,729 : INFO : PROGRESS: at 11.99% examples, 712333 words/s, in_qsize 8, out_qsize 2\n",
      "2017-02-01 19:34:21,733 : INFO : PROGRESS: at 12.47% examples, 707320 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:22,733 : INFO : PROGRESS: at 12.98% examples, 703806 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:23,735 : INFO : PROGRESS: at 13.44% examples, 698163 words/s, in_qsize 7, out_qsize 3\n",
      "2017-02-01 19:34:24,736 : INFO : PROGRESS: at 14.01% examples, 698979 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:25,739 : INFO : PROGRESS: at 14.53% examples, 696900 words/s, in_qsize 8, out_qsize 6\n",
      "2017-02-01 19:34:26,742 : INFO : PROGRESS: at 15.10% examples, 697004 words/s, in_qsize 6, out_qsize 3\n",
      "2017-02-01 19:34:27,742 : INFO : PROGRESS: at 15.68% examples, 697908 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:28,747 : INFO : PROGRESS: at 16.25% examples, 698416 words/s, in_qsize 6, out_qsize 2\n",
      "2017-02-01 19:34:29,748 : INFO : PROGRESS: at 16.78% examples, 697327 words/s, in_qsize 7, out_qsize 4\n",
      "2017-02-01 19:34:30,752 : INFO : PROGRESS: at 17.28% examples, 694998 words/s, in_qsize 5, out_qsize 2\n",
      "2017-02-01 19:34:31,752 : INFO : PROGRESS: at 17.75% examples, 691306 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:32,755 : INFO : PROGRESS: at 18.26% examples, 689768 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:33,756 : INFO : PROGRESS: at 18.85% examples, 690933 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:34:34,759 : INFO : PROGRESS: at 19.43% examples, 691843 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:35,760 : INFO : PROGRESS: at 20.00% examples, 692370 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:34:36,764 : INFO : PROGRESS: at 20.45% examples, 688934 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:37,765 : INFO : PROGRESS: at 20.95% examples, 687984 words/s, in_qsize 6, out_qsize 3\n",
      "2017-02-01 19:34:38,766 : INFO : PROGRESS: at 21.49% examples, 687544 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-01 19:34:39,767 : INFO : PROGRESS: at 21.89% examples, 682673 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:34:40,768 : INFO : PROGRESS: at 22.42% examples, 682250 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:41,769 : INFO : PROGRESS: at 22.98% examples, 682788 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:42,776 : INFO : PROGRESS: at 23.57% examples, 683561 words/s, in_qsize 5, out_qsize 4\n",
      "2017-02-01 19:34:43,776 : INFO : PROGRESS: at 24.17% examples, 685264 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:34:44,775 : INFO : PROGRESS: at 24.75% examples, 685627 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:45,778 : INFO : PROGRESS: at 25.36% examples, 686815 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:34:46,779 : INFO : PROGRESS: at 25.94% examples, 687595 words/s, in_qsize 8, out_qsize 3\n",
      "2017-02-01 19:34:47,783 : INFO : PROGRESS: at 26.54% examples, 689172 words/s, in_qsize 5, out_qsize 3\n",
      "2017-02-01 19:34:48,783 : INFO : PROGRESS: at 27.13% examples, 690113 words/s, in_qsize 8, out_qsize 2\n",
      "2017-02-01 19:34:49,782 : INFO : PROGRESS: at 27.68% examples, 690091 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:50,785 : INFO : PROGRESS: at 28.26% examples, 690620 words/s, in_qsize 7, out_qsize 5\n",
      "2017-02-01 19:34:51,784 : INFO : PROGRESS: at 28.81% examples, 690760 words/s, in_qsize 1, out_qsize 0\n",
      "2017-02-01 19:34:52,786 : INFO : PROGRESS: at 29.34% examples, 690075 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:34:53,790 : INFO : PROGRESS: at 29.92% examples, 690558 words/s, in_qsize 4, out_qsize 3\n",
      "2017-02-01 19:34:54,787 : INFO : PROGRESS: at 30.49% examples, 691245 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:34:55,788 : INFO : PROGRESS: at 31.00% examples, 690390 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:56,790 : INFO : PROGRESS: at 31.58% examples, 690911 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:57,791 : INFO : PROGRESS: at 32.07% examples, 689365 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:34:58,793 : INFO : PROGRESS: at 32.65% examples, 690003 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:34:59,792 : INFO : PROGRESS: at 33.24% examples, 690679 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:00,798 : INFO : PROGRESS: at 33.80% examples, 690679 words/s, in_qsize 7, out_qsize 2\n",
      "2017-02-01 19:35:01,803 : INFO : PROGRESS: at 34.38% examples, 691442 words/s, in_qsize 5, out_qsize 3\n",
      "2017-02-01 19:35:02,804 : INFO : PROGRESS: at 34.98% examples, 692178 words/s, in_qsize 6, out_qsize 3\n",
      "2017-02-01 19:35:03,805 : INFO : PROGRESS: at 35.57% examples, 692691 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:04,807 : INFO : PROGRESS: at 36.17% examples, 693592 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:05,806 : INFO : PROGRESS: at 36.74% examples, 694018 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:35:06,806 : INFO : PROGRESS: at 37.32% examples, 694526 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:07,811 : INFO : PROGRESS: at 37.91% examples, 694865 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:35:08,813 : INFO : PROGRESS: at 38.50% examples, 695621 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:09,816 : INFO : PROGRESS: at 39.11% examples, 696381 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:10,816 : INFO : PROGRESS: at 39.71% examples, 697092 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:11,818 : INFO : PROGRESS: at 40.28% examples, 697517 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:12,819 : INFO : PROGRESS: at 40.88% examples, 698443 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-01 19:35:13,820 : INFO : PROGRESS: at 41.46% examples, 698785 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:14,822 : INFO : PROGRESS: at 42.04% examples, 698981 words/s, in_qsize 8, out_qsize 2\n",
      "2017-02-01 19:35:15,823 : INFO : PROGRESS: at 42.63% examples, 699545 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:16,823 : INFO : PROGRESS: at 43.23% examples, 700205 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:17,826 : INFO : PROGRESS: at 43.82% examples, 700650 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:35:18,828 : INFO : PROGRESS: at 44.43% examples, 701286 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:19,831 : INFO : PROGRESS: at 45.04% examples, 701701 words/s, in_qsize 7, out_qsize 2\n",
      "2017-02-01 19:35:20,831 : INFO : PROGRESS: at 45.62% examples, 702053 words/s, in_qsize 5, out_qsize 2\n",
      "2017-02-01 19:35:21,831 : INFO : PROGRESS: at 46.24% examples, 702752 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-01 19:35:22,834 : INFO : PROGRESS: at 46.83% examples, 703206 words/s, in_qsize 6, out_qsize 4\n",
      "2017-02-01 19:35:23,838 : INFO : PROGRESS: at 47.43% examples, 703854 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:35:24,836 : INFO : PROGRESS: at 48.02% examples, 704286 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:25,836 : INFO : PROGRESS: at 48.61% examples, 704649 words/s, in_qsize 8, out_qsize 2\n",
      "2017-02-01 19:35:26,838 : INFO : PROGRESS: at 49.22% examples, 705332 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:27,838 : INFO : PROGRESS: at 49.81% examples, 705588 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:28,840 : INFO : PROGRESS: at 50.40% examples, 706130 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:29,841 : INFO : PROGRESS: at 51.01% examples, 706856 words/s, in_qsize 2, out_qsize 1\n",
      "2017-02-01 19:35:30,843 : INFO : PROGRESS: at 51.60% examples, 707060 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:31,846 : INFO : PROGRESS: at 52.20% examples, 707367 words/s, in_qsize 6, out_qsize 3\n",
      "2017-02-01 19:35:32,845 : INFO : PROGRESS: at 52.81% examples, 707916 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:33,847 : INFO : PROGRESS: at 53.39% examples, 708105 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:34,848 : INFO : PROGRESS: at 54.00% examples, 708667 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:35,850 : INFO : PROGRESS: at 54.59% examples, 708959 words/s, in_qsize 8, out_qsize 2\n",
      "2017-02-01 19:35:36,854 : INFO : PROGRESS: at 55.19% examples, 709280 words/s, in_qsize 4, out_qsize 3\n",
      "2017-02-01 19:35:37,855 : INFO : PROGRESS: at 55.80% examples, 709796 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:38,855 : INFO : PROGRESS: at 56.41% examples, 710254 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-01 19:35:39,855 : INFO : PROGRESS: at 57.00% examples, 710725 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:40,857 : INFO : PROGRESS: at 57.61% examples, 711044 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:41,860 : INFO : PROGRESS: at 58.21% examples, 711372 words/s, in_qsize 6, out_qsize 2\n",
      "2017-02-01 19:35:42,862 : INFO : PROGRESS: at 58.80% examples, 711620 words/s, in_qsize 8, out_qsize 3\n",
      "2017-02-01 19:35:43,860 : INFO : PROGRESS: at 59.40% examples, 711914 words/s, in_qsize 6, out_qsize 2\n",
      "2017-02-01 19:35:44,863 : INFO : PROGRESS: at 60.00% examples, 712401 words/s, in_qsize 8, out_qsize 2\n",
      "2017-02-01 19:35:45,863 : INFO : PROGRESS: at 60.61% examples, 712925 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:35:46,866 : INFO : PROGRESS: at 61.20% examples, 713160 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:47,865 : INFO : PROGRESS: at 61.80% examples, 713651 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-01 19:35:48,866 : INFO : PROGRESS: at 62.41% examples, 713971 words/s, in_qsize 4, out_qsize 0\n",
      "2017-02-01 19:35:49,866 : INFO : PROGRESS: at 63.00% examples, 714244 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:35:50,867 : INFO : PROGRESS: at 63.61% examples, 714614 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:35:51,867 : INFO : PROGRESS: at 64.21% examples, 714980 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:52,870 : INFO : PROGRESS: at 64.80% examples, 714890 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:35:53,875 : INFO : PROGRESS: at 65.37% examples, 714827 words/s, in_qsize 5, out_qsize 6\n",
      "2017-02-01 19:35:54,874 : INFO : PROGRESS: at 65.93% examples, 714556 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:35:55,876 : INFO : PROGRESS: at 66.38% examples, 713283 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:56,878 : INFO : PROGRESS: at 66.93% examples, 713097 words/s, in_qsize 0, out_qsize 1\n",
      "2017-02-01 19:35:57,877 : INFO : PROGRESS: at 67.51% examples, 713175 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:58,879 : INFO : PROGRESS: at 68.07% examples, 713093 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:35:59,879 : INFO : PROGRESS: at 68.67% examples, 713435 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:00,881 : INFO : PROGRESS: at 69.27% examples, 713700 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:01,885 : INFO : PROGRESS: at 69.84% examples, 713619 words/s, in_qsize 7, out_qsize 4\n",
      "2017-02-01 19:36:02,884 : INFO : PROGRESS: at 70.36% examples, 713188 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:03,886 : INFO : PROGRESS: at 70.87% examples, 712701 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:04,901 : INFO : PROGRESS: at 71.40% examples, 712161 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:05,902 : INFO : PROGRESS: at 71.89% examples, 711279 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:06,903 : INFO : PROGRESS: at 72.41% examples, 710861 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:36:07,906 : INFO : PROGRESS: at 72.94% examples, 710390 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:08,909 : INFO : PROGRESS: at 73.46% examples, 709837 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:09,912 : INFO : PROGRESS: at 74.05% examples, 710128 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:36:10,915 : INFO : PROGRESS: at 74.65% examples, 710294 words/s, in_qsize 5, out_qsize 2\n",
      "2017-02-01 19:36:11,915 : INFO : PROGRESS: at 75.12% examples, 709345 words/s, in_qsize 5, out_qsize 3\n",
      "2017-02-01 19:36:12,916 : INFO : PROGRESS: at 75.62% examples, 708708 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:36:13,920 : INFO : PROGRESS: at 76.08% examples, 707711 words/s, in_qsize 7, out_qsize 4\n",
      "2017-02-01 19:36:14,920 : INFO : PROGRESS: at 76.63% examples, 707517 words/s, in_qsize 5, out_qsize 2\n",
      "2017-02-01 19:36:15,920 : INFO : PROGRESS: at 77.09% examples, 706625 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:36:16,921 : INFO : PROGRESS: at 77.69% examples, 706852 words/s, in_qsize 6, out_qsize 2\n",
      "2017-02-01 19:36:17,921 : INFO : PROGRESS: at 78.24% examples, 706729 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:36:18,921 : INFO : PROGRESS: at 78.82% examples, 706850 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:19,924 : INFO : PROGRESS: at 79.42% examples, 707114 words/s, in_qsize 5, out_qsize 3\n",
      "2017-02-01 19:36:20,925 : INFO : PROGRESS: at 80.00% examples, 707274 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:36:21,930 : INFO : PROGRESS: at 80.62% examples, 707765 words/s, in_qsize 6, out_qsize 3\n",
      "2017-02-01 19:36:22,928 : INFO : PROGRESS: at 81.23% examples, 708190 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:23,930 : INFO : PROGRESS: at 81.84% examples, 708622 words/s, in_qsize 7, out_qsize 2\n",
      "2017-02-01 19:36:24,932 : INFO : PROGRESS: at 82.43% examples, 708826 words/s, in_qsize 7, out_qsize 3\n",
      "2017-02-01 19:36:25,933 : INFO : PROGRESS: at 83.04% examples, 709216 words/s, in_qsize 5, out_qsize 4\n",
      "2017-02-01 19:36:26,931 : INFO : PROGRESS: at 83.66% examples, 709560 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:27,931 : INFO : PROGRESS: at 84.25% examples, 709770 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:28,932 : INFO : PROGRESS: at 84.86% examples, 709955 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:29,932 : INFO : PROGRESS: at 85.47% examples, 710260 words/s, in_qsize 6, out_qsize 2\n",
      "2017-02-01 19:36:30,932 : INFO : PROGRESS: at 86.06% examples, 710355 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:31,934 : INFO : PROGRESS: at 86.66% examples, 710648 words/s, in_qsize 5, out_qsize 3\n",
      "2017-02-01 19:36:32,934 : INFO : PROGRESS: at 87.27% examples, 711041 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:33,935 : INFO : PROGRESS: at 87.89% examples, 711431 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:36:34,935 : INFO : PROGRESS: at 88.50% examples, 711774 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:35,937 : INFO : PROGRESS: at 89.09% examples, 712004 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:36:36,936 : INFO : PROGRESS: at 89.70% examples, 712208 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:37,937 : INFO : PROGRESS: at 90.30% examples, 712556 words/s, in_qsize 7, out_qsize 5\n",
      "2017-02-01 19:36:38,939 : INFO : PROGRESS: at 90.92% examples, 712958 words/s, in_qsize 8, out_qsize 1\n",
      "2017-02-01 19:36:39,939 : INFO : PROGRESS: at 91.52% examples, 713180 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:40,941 : INFO : PROGRESS: at 92.14% examples, 713489 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:36:41,941 : INFO : PROGRESS: at 92.76% examples, 713844 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:42,941 : INFO : PROGRESS: at 93.35% examples, 714015 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:36:43,942 : INFO : PROGRESS: at 93.95% examples, 714208 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:44,942 : INFO : PROGRESS: at 94.57% examples, 714531 words/s, in_qsize 8, out_qsize 0\n",
      "2017-02-01 19:36:45,944 : INFO : PROGRESS: at 95.18% examples, 714778 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:36:46,947 : INFO : PROGRESS: at 95.78% examples, 714961 words/s, in_qsize 4, out_qsize 2\n",
      "2017-02-01 19:36:47,943 : INFO : PROGRESS: at 96.38% examples, 715167 words/s, in_qsize 7, out_qsize 0\n",
      "2017-02-01 19:36:48,948 : INFO : PROGRESS: at 96.99% examples, 715510 words/s, in_qsize 5, out_qsize 4\n",
      "2017-02-01 19:36:49,945 : INFO : PROGRESS: at 97.58% examples, 715644 words/s, in_qsize 8, out_qsize 3\n",
      "2017-02-01 19:36:50,950 : INFO : PROGRESS: at 98.21% examples, 715947 words/s, in_qsize 5, out_qsize 3\n",
      "2017-02-01 19:36:51,949 : INFO : PROGRESS: at 98.82% examples, 716252 words/s, in_qsize 7, out_qsize 1\n",
      "2017-02-01 19:36:52,949 : INFO : PROGRESS: at 99.42% examples, 716438 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-01 19:36:53,923 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-02-01 19:36:53,926 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-01 19:36:53,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-01 19:36:53,928 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-01 19:36:53,928 : INFO : training on 1039875000 raw words (124851566 effective words) took 174.2s, 716573 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 191.618520975 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# TIMER\n",
    "import time\n",
    "start_time = time.time()\n",
    "# END TIMER\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = gensim.models.Word2Vec(processed_texts, min_count=1, workers=4, sg=0, window=5)\n",
    "\n",
    "# TIMER\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-01 18:32:05,026 : INFO : storing 141295x100 projection weights into word2vec/w2v-padded.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_word2vec_format('word2vec/w2v-padded.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model = gensim.models.Word2Vec.load_word2vec_format('word2vec/w2v-padded.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
