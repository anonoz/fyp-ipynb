{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec (DBOW) on IMDB dataset\n",
    "\n",
    "Steps:\n",
    "* Tokenize punctuations as if they are their own words\n",
    "* Determine the longest review's word count, then pad other reviews so that they are all as long as the longest review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is disabled, cuDNN 5105)\n",
      "/home/anonoz/anaconda2/envs/tensorflow/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import gensim\n",
    "import logging\n",
    "from text_tokenizer import tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Easily changable settings\n",
    "# We will only train from training/unlabeled set\n",
    "text_corpus_files = ['aclImdb/train/pos/*.txt', 'aclImdb/train/neg/*.txt', 'aclImdb/train/unsup/*.txt']\n",
    "word_vector_dims = 100\n",
    "model_save_as = \"word2vec/d2v-imdb-dbow-{0}d.modelxx\".format(word_vector_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file 75000\n",
      "Longest text list: 2773\n"
     ]
    }
   ],
   "source": [
    "processed_texts = []\n",
    "file_names = []\n",
    "file_count = 0\n",
    "for folder_files in text_corpus_files:\n",
    "    for text_file in glob.glob(folder_files):\n",
    "        with(open(text_file, 'r')) as f:\n",
    "            processed_texts.append(tokenize(f.read()))\n",
    "            file_names.append(text_file)\n",
    "            file_count += 1\n",
    "            if file_count % 100 == 0:\n",
    "                sys.stdout.write('\\rLoading text file {0:d}'.format(file_count))\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "max_processed_text_len = len(max(processed_texts, key=len))\n",
    "print('\\nLongest text list: {0:d}'.format(max_processed_text_len))\n",
    "# for i, text_list in enumerate(processed_texts):\n",
    "#     processed_texts[i] = pad_text_list(text_list, pad_width=max_processed_text_len)\n",
    "#     if (i + 1) % 1000 == 0:\n",
    "#         sys.stdout.write('\\rPadding text list {0:d}'.format(i+1))\n",
    "#         sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LabeledReview(object):\n",
    "    def __init__(self, docs_list, labels_list):\n",
    "        self.docs_list = docs_list\n",
    "        self.labels_list = labels_list\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.docs_list):\n",
    "            yield TaggedDocument(words=doc, tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning epoch 1\n",
      "Beginning epoch 2\n",
      "Beginning epoch 3\n",
      "Beginning epoch 4\n",
      "Beginning epoch 5\n",
      "Beginning epoch 6\n",
      "Beginning epoch 7\n",
      "Beginning epoch 8\n",
      "Beginning epoch 9\n",
      "Beginning epoch 10\n",
      "--- 1243.59263802 seconds ---\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "it = LabeledReview(processed_texts, file_names)\n",
    "\n",
    "model = Doc2Vec(size=word_vector_dims, window=8, min_count=1, workers=4, alpha=0.025, min_alpha=0.025, dm=0)\n",
    "model.build_vocab(it)\n",
    "\n",
    "# TIMER\n",
    "import time\n",
    "start_time = time.time()\n",
    "# END TIMER\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"Beginning epoch {0:d}\".format(epoch+1))\n",
    "    model.train(it)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha\n",
    "    model.train(it)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(model_save_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_model = gensim.models.Doc2Vec.load_word2vec_format('word2vec/d2v-padded.bin', binary=True)\n",
    "test_model = Doc2Vec.load(model_save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'electri', 0.44531017541885376),\n",
       " (u'guttridge', 0.4025043249130249),\n",
       " (u'municipalians', 0.392833411693573),\n",
       " (u'unreconstructed', 0.39157259464263916),\n",
       " (u'bumpkins', 0.3887981176376343),\n",
       " (u'tiedied', 0.3848254084587097),\n",
       " (u'murad', 0.3837975263595581),\n",
       " (u'dobro', 0.38057032227516174),\n",
       " (u'verhopven', 0.3724980652332306),\n",
       " (u'operable', 0.37155359983444214)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.most_similar('robot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer_vector(text):\n",
    "    test_model.infer_vector(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infer_vector('Apple decides to kill ornage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17231174, -0.37082675,  0.28180525,  0.03994866,  0.20616618,\n",
       "       -0.0208779 ,  0.29593143, -0.11548571, -0.05137589, -0.30965227,\n",
       "        0.31568965, -0.54743063,  0.50441384,  0.39466131, -0.23167916,\n",
       "       -0.51313728, -0.23646614, -0.37890327, -0.41118169,  0.07404428,\n",
       "        0.37155417,  0.15627038, -0.00802261, -0.41750944, -0.17853852,\n",
       "        0.43775645, -0.52300262,  0.14638248,  0.07199747,  0.59722763,\n",
       "        0.31002092, -0.29298946, -0.1716281 , -0.27529186, -0.10400043,\n",
       "       -0.27337196,  0.15527037, -0.1680723 , -0.36725488,  0.22694018,\n",
       "        0.17879798, -0.06368355,  0.44016534, -0.52956432, -0.1154929 ,\n",
       "       -0.41443637, -0.0083477 , -0.02827242, -0.19422367,  0.10291863,\n",
       "       -0.2656284 , -0.5024243 ,  0.09802187,  0.36961812,  0.22301677,\n",
       "        0.26114619, -0.54922807,  0.1528462 , -0.47032312, -0.14636959,\n",
       "        0.04742416,  0.49284756,  0.0812405 ,  0.18190728, -0.27619174,\n",
       "       -0.15752394,  0.15506928,  0.64426523,  0.24821791,  0.9936294 ,\n",
       "       -0.09973796,  0.20524459,  0.26958099,  0.08144885,  0.24215984,\n",
       "       -0.08061995,  0.30374268, -0.52799714,  0.79481715, -0.18886897,\n",
       "        0.06115104, -0.0309645 ,  0.01255385, -0.02969273, -0.21106951,\n",
       "        0.15568435,  0.03427406, -0.29232049,  0.17822003, -0.13874348,\n",
       "       -0.44857073, -0.16658993,  0.10571479,  0.25347614,  0.08901719,\n",
       "        0.1399748 , -0.02614327,  0.26377267,  0.01072108,  0.14469722], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.infer_vector('Can also accept string but who knows?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
