{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec with how Yoon Kim did it\n",
    "\n",
    "Steps:\n",
    "* Tokenize punctuations as if they are their own words\n",
    "* Determine the longest review's word count, then pad other reviews so that they are all as long as the longest review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is disabled, cuDNN 5105)\n",
      "/home/anonoz/anaconda2/envs/tensorflow/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import gensim\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Easily changable settings\n",
    "# We will only train from training/unlabeled set\n",
    "text_corpus_files = ['aclImdb/train/pos/*.txt', 'aclImdb/train/neg/*.txt', 'aclImdb/train/unsup/*.txt']\n",
    "word_vector_dims = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #1 Remove HTML (inspired by Kaggle)\n",
    "    text = BeautifulSoup(text, \"html.parser\").getText()\n",
    "\n",
    "    #2 Tokenize (stolen from Yoon Kim's CNN)\n",
    "    text = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", text)     \n",
    "    text = re.sub(r\"\\'s\", \" \\'s\", text) \n",
    "    text = re.sub(r\"\\'ve\", \" \\'ve\", text) \n",
    "    text = re.sub(r\"n\\'t\", \" n\\'t\", text) \n",
    "    text = re.sub(r\"\\'re\", \" \\'re\", text) \n",
    "    text = re.sub(r\"\\'d\", \" \\'d\", text) \n",
    "    text = re.sub(r\"\\'ll\", \" \\'ll\", text) \n",
    "    text = re.sub(r\",\", \" , \", text) \n",
    "    text = re.sub(r\"!\", \" ! \", text) \n",
    "    text = re.sub(r\"\\(\", \" \\( \", text) \n",
    "    text = re.sub(r\"\\)\", \" \\) \", text) \n",
    "    text = re.sub(r\"\\?\", \" \\? \", text) \n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    #3 Lower cap\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_text_list(text_list, pad_token=\"<PAD/>\", pad_width=0):\n",
    "    return text_list + ([pad_token] * (pad_width - len(text_list)))\n",
    "\n",
    "def text_to_padded_list(text, pad_token=\"<PAD/>\", pad_width=0):\n",
    "    text_list = preprocess_text(text).split()\n",
    "    return pad_text_list(text_list, pad_token, pad_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file 75000\n",
      "Longest text list: 2773\n"
     ]
    }
   ],
   "source": [
    "processed_texts = []\n",
    "file_names = []\n",
    "file_count = 0\n",
    "for folder_files in text_corpus_files:\n",
    "    for text_file in glob.glob(folder_files):\n",
    "        with(open(text_file, 'r')) as f:\n",
    "            processed_texts.append(text_to_padded_list(f.read()))\n",
    "            file_names.append(text_file)\n",
    "            file_count += 1\n",
    "            if file_count % 100 == 0:\n",
    "                sys.stdout.write('\\rLoading text file {0:d}'.format(file_count))\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "max_processed_text_len = len(max(processed_texts, key=len))\n",
    "print('\\nLongest text list: {0:d}'.format(max_processed_text_len))\n",
    "# for i, text_list in enumerate(processed_texts):\n",
    "#     processed_texts[i] = pad_text_list(text_list, pad_width=max_processed_text_len)\n",
    "#     if (i + 1) % 1000 == 0:\n",
    "#         sys.stdout.write('\\rPadding text list {0:d}'.format(i+1))\n",
    "#         sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LabeledReview(object):\n",
    "    def __init__(self, docs_list, labels_list):\n",
    "        self.docs_list = docs_list\n",
    "        self.labels_list = labels_list\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.docs_list):\n",
    "            yield TaggedDocument(words=doc, tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning epoch 1\n",
      "Beginning epoch 2\n",
      "Beginning epoch 3\n",
      "Beginning epoch 4\n",
      "Beginning epoch 5\n",
      "Beginning epoch 6\n",
      "Beginning epoch 7\n",
      "Beginning epoch 8\n",
      "Beginning epoch 9\n",
      "Beginning epoch 10\n"
     ]
    }
   ],
   "source": [
    "it = LabeledReview(processed_texts, file_names)\n",
    "\n",
    "model = Doc2Vec(size=100, window=8, min_count=1, workers=4, alpha=0.025, min_alpha=0.025, dm=1)\n",
    "model.build_vocab(it)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"Beginning epoch {0:d}\".format(epoch+1))\n",
    "    model.train(it)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha\n",
    "    model.train(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_word2vec_format('word2vec/d2v-dm-50d.bin', binary=True)\n",
    "model.save('word2vec/d2v-dm-50d.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_model = gensim.models.Doc2Vec.load_word2vec_format('word2vec/d2v-padded.bin', binary=True)\n",
    "test_model = Doc2Vec.load('word2vec/d2v-dm-50d.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'boy', 0.7213273048400879),\n",
       " (u'policeman', 0.7198787331581116),\n",
       " (u'maniac', 0.7197606563568115),\n",
       " (u'nerd', 0.7159204483032227),\n",
       " (u'lawyer', 0.7151718139648438),\n",
       " (u'kid', 0.711284875869751),\n",
       " (u'prostitute', 0.7106501460075378),\n",
       " (u'thief', 0.7083243131637573),\n",
       " (u'doctor', 0.7071986794471741),\n",
       " (u'woman', 0.7043994069099426)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.most_similar('robot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer_vector(text):\n",
    "    test_model.infer_vector(text_to_padded_list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infer_vector('Apple decides to kill ornage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01595143, -0.02850123, -0.00850443,  0.02607614, -0.00635684,\n",
       "        0.00328236, -0.02458174,  0.01933051,  0.00154752, -0.00923351,\n",
       "        0.01828594,  0.02338634,  0.04594881,  0.01582849, -0.01805806,\n",
       "        0.01653051, -0.00788338,  0.00617298, -0.00092188,  0.00387195,\n",
       "       -0.03214197,  0.03041311,  0.02434262, -0.05064768, -0.02673751,\n",
       "        0.00489244,  0.06051378, -0.01317   , -0.04376006,  0.04648232,\n",
       "       -0.03026671, -0.00244751, -0.01427396, -0.02382843,  0.00972601,\n",
       "        0.03035809,  0.00535701, -0.02562642, -0.00141815,  0.04683141,\n",
       "       -0.01686425,  0.00672396,  0.01222186, -0.02510577,  0.0065539 ,\n",
       "       -0.02291234,  0.02027738, -0.0202756 ,  0.00473335,  0.00840169,\n",
       "       -0.01521209, -0.07518742, -0.02587005,  0.04780743,  0.00617817,\n",
       "        0.05715486,  0.0128863 ,  0.00041511, -0.0046965 ,  0.01947872,\n",
       "       -0.04566262,  0.0783381 , -0.00718412, -0.03953593, -0.02257931,\n",
       "        0.00202419,  0.01255951, -0.04387324, -0.03954568, -0.04315242,\n",
       "        0.03683737,  0.0148882 ,  0.05025676,  0.03454089,  0.01901432,\n",
       "       -0.01301331,  0.00767652,  0.05027074, -0.00095928, -0.00903828,\n",
       "        0.00273123,  0.01490603, -0.00063278,  0.00481315, -0.00139432,\n",
       "       -0.05427662,  0.02982292, -0.01008711,  0.01500369, -0.0435095 ,\n",
       "       -0.01958627, -0.01903947,  0.03287746, -0.01475406,  0.0082627 ,\n",
       "        0.05805502, -0.03277039,  0.03692928, -0.01775741,  0.01401128], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.infer_vector('Can also accept string but who knows?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
